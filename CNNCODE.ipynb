{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note to run all cells from top to bottom(i.e first to last)\n",
    "#The below cell is used to convert the dataset into readable data for training and saves the X and Y values as pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = \"W:/Datasets/\"\n",
    "IMG_SIZE = 70\n",
    "CATEGORIES = [\"no_mask\", \"mask\"]\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES: \n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):  \n",
    "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE) \n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "            training_data.append([new_array, class_num])  \n",
    "        \n",
    "create_training_data()\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below cell is used for training the model.\n",
    "#First it reads both the training images and their labels\n",
    "#Then it creates the CNN using two convolutional layers and 2 dense layers.\n",
    "#It will split the dataset for a 0.3 validation split and \n",
    "#Save the model as CNN7.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "NAME = \"Newly and Fresh\"\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "y = np.array(y)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "    \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=2, validation_split=0.3, callbacks=[tensorboard])\n",
    "\n",
    "model.save('CNN7.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code loads the model for predictions in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = tf.keras.models.load_model(\"CNN7.model\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code is for predicting images using the model.\n",
    "#It will print the image in gray scale as well as the according prediction\n",
    "#To change the file you are predicting just change the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CATEGORIES = [\"no_mask\", \"mask\"]\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 70 \n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    plt.imshow(new_array, cmap='gray')  \n",
    "    plt.show()  \n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "prediction = model.predict([prepare('W:/Datasets/mask.jpg')]) #Change file path for the image to be predicted\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code is used to iterate over the test dataset in order to test the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = \"W:/Datasets/\"\n",
    "IMG_SIZE = 70\n",
    "CATEGORIES = [\"no_mask_test\", \"mask_test\"]\n",
    "CATEGORIES1 = [\"no_mask\", \"mask\"]\n",
    "\n",
    "\n",
    "def check_accuracy():\n",
    "    noMaskSize = 0\n",
    "    maskSize = 0\n",
    "    numCor = 0\n",
    "    numInc = 0\n",
    "    for category in CATEGORIES:  \n",
    "        path = os.path.join(DATADIR,category)  \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):  \n",
    "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "            prediction = model.predict([new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)])\n",
    "            if (category == \"mask_test\"):\n",
    "                maskSize = maskSize + 1\n",
    "                numCor = numCor + int(prediction[0][0])\n",
    "            if (category == \"no_mask_test\"):\n",
    "                noMaskSize = noMaskSize + 1\n",
    "                numInc = numInc + int(prediction[0][0])\n",
    "    numTotal = noMaskSize + maskSize\n",
    "    accuracy = (numCor + (noMaskSize - numInc))/numTotal\n",
    "    print(accuracy)\n",
    "    \n",
    "check_accuracy()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
